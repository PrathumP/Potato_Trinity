# -*- coding: utf-8 -*-
"""leafdetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zAz7em-9SIg5s7Cn2r1SZsVporRKpzLu
"""

print("Python")

# !pwd

# !ls /content/drive/MyDrive/

# from google.colab import files
# uploaded=files.upload()

# from google.colab import drive
# drive.mount('/content/drive')

# import zipfile
# import io
# zip_file_path='Dataset for CNN.zip'
# with zipfile.ZipFile(zip_file_path,'r') as zip_ref:
#   zip_ref.extractall('data')

# Commented out IPython magic to ensure Python compatibility.
# isse upar ka sb comment kr dena
import torch

import os
import torchvision
import numpy as np
import matplotlib
import torch
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
from torchvision.datasets import ImageFolder
from torchvision.datasets import DatasetFolder
import torchvision.transforms as transforms
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
from torchvision.utils import make_grid
from torch.utils.data.dataloader import DataLoader
from torch.utils.data import random_split
# %matplotlib inline

from torchvision.transforms import ToTensor
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os

# Define the data path and label mapping
data_path = 'drive/MyDrive/Potato'
label_map = {
    'Potato___healthy': 0,
    'Potato___Early_blight': 1,
    'Potato___Late_blight': 2
}

# Initialize empty lists to store images and labels
images = []
labels = []

# Iterate through each folder in the data path
for folder_name in os.listdir(data_path):
    if folder_name in label_map:
        folder_path = os.path.join(data_path, folder_name)
        for file_name in os.listdir(folder_path):
                # Construct the full path to the image file
                image_path = os.path.join(folder_path, file_name)

                # Load the image using PIL (Pillow)
                # image = Image.open(image_path).convert('RGB')
                # can do above too , like idk tbh
                image = Image.open(image_path)

                # Append the image and corresponding label to the lists
                images.append(image)
                labels.append(label_map[folder_name])

# Define a custom dataset class
class CustomDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

# Create an instance of CustomDataset with transformations
transform = ToTensor()  # Convert PIL image to PyTorch tensor
custom_dataset = CustomDataset(images, labels, transform=transform)

# # Create a DataLoader for the custom dataset
# batch_size = 32
# data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)

# # Test the DataLoader by iterating through a few batches
# for batch_images, batch_labels in data_loader:
#     print("Batch images shape:", batch_images.shape)
#     print("Batch labels:", batch_labels)
#     break  # Stop after processing the first batch for demonstration

"""so, till here, we have got the images as we want.
label :
0-healthy
1- early
2- late

below is example of how we can load image and label from the custom_dataset
which actually have the dataset as collective
also randomization would be needed for it as it has been done through loop


"""

image,label=custom_dataset[0]
print(image.shape)
# Assuming 'image_tensor' is the tensor with shape [3, 256, 256]
# You can replace 'image_tensor' with your specific tensor variable

# Convert the tensor image to a numpy array
image_np = image.permute(1, 2, 0).cpu().numpy()  # Permute dimensions for matplotlib (HWC)

# Clip the pixel values to be within [0, 1] (assuming RGB image)
image_np = image_np.clip(0, 1)

# Display the image using matplotlib
plt.imshow(image_np)
plt.axis('off')  # Turn off axis labels
plt.show()
print(label)

len(custom_dataset)

def show_example(img, label):   #printing the images
    print('Label: ', dataset.classes[label], "("+str(label)+")")
    plt.imshow(img.permute(1, 2, 0))

random_seed = 42
torch.manual_seed(random_seed);

val_size = 450
train_size = len(custom_dataset) - val_size

train_ds, val_ds = random_split(custom_dataset, [train_size, val_size])
len(train_ds), len(val_ds)

from torch.utils.data.dataloader import DataLoader

batch_size=48

train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)

len(train_loader) #54 batches of training data

len(val_loader)  #8 batches of validation data

import torch.nn as nn
import torch.nn.functional as F

class ImageClassification(nn.Module):
    def training_step(self, batch):
        images, labels = batch
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        return loss

    def validation_step(self, batch):
        images, labels = batch
        out = self(images)                    # Generate predictions for each batch
        loss = F.cross_entropy(out, labels)   # Calculate loss for each batch
        acc = accuracy(out, labels)           # Calculate accuracy for each batch
        return {'val_loss': loss.detach(), 'val_acc': acc}

    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}

    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss'], result['val_acc']))

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

class PotatoClassification(ImageClassification):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(                        #constructs the NN
            nn.Conv2d(3, 32, kernel_size=3, padding=1),   #input is 3 x 256 x 256
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # output: 64 x 128 x 128

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # output: 128 x 64 x 64

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # output: 256 x 32 x 32

            nn.Flatten(),                   #Flattens for the ANN
            nn.Linear(256*32*32, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 3))

    def forward(self, xb):
        return self.network(xb)             #For the forward pass of the model.

def get_default_device():             #For GPU
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')

def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

model = PotatoClassification()
model

torch.cuda.is_available()

def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')

def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

device = get_default_device()
device

train_loader = DeviceDataLoader(train_loader, device) #moves the train,val data and model to the GPU
val_loader = DeviceDataLoader(val_loader, device)
to_device(model, device)

@torch.no_grad()
def evaluate(model, val_loader):                #evaluates validation accuracy for every single batch across the entire val_data.
    model.eval()                                #sets the PyTorch model to evaluation mode
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    history = []
    optimizer = opt_func(model.parameters(), lr)
    for epoch in range(epochs):
        # Training Phase
        model.train()                            #tells pytorch that the model is training.
        train_losses = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result)
        history.append(result)
    return history

model = to_device(PotatoClassification(), device)
model

evaluate(model, val_loader)

num_epochs = 10
opt_func = torch.optim.Adam
lr = 0.001

history = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)

img,_=custom_dataset[0]
def predict(img):
  return "Potato__healthy"







"""

---


So bro, this was the dataset and ignore the random shit below, i didn't cleared it"""

# from torch.utils.data import TensorDataset, DataLoader
# from torchvision.transforms import ToTensor
# import random

# # Assuming 'images' and 'labels' are lists containing your data
# # Convert lists to tensors
# images_tensor = torch.stack([ToTensor()(img) for img in images])
# labels_tensor = torch.tensor(labels)

# # Create a TensorDataset from images and labels tensors
# dataset = TensorDataset(images_tensor, labels_tensor)
# # Get the total number of samples in the dataset
# num_samples = len(dataset)

# # Generate a random permutation of indices
# indices = list(range(num_samples))
# random.shuffle(indices)

# # Create a new TensorDataset with shuffled indices
# shuffled_dataset = TensorDataset(images_tensor[indices], labels_tensor[indices])

# # Now 'shuffled_dataset' contains samples in a randomized order
# # You can use 'shuffled_dataset' for further processing or iteration

# # this is the desired dataset with what we've worked on in lectures


# # Create a DataLoader for the dataset with shuffling and batching
# # batch_size = 32
# # dataset_shuffle= DataLoader(dataset, batch_size=batch_size, shuffle=True)
# img,lbl=shuffled_dataset[2]
# print(lbl)

# # Iterate over batches in the DataLoader
# for batch_images, batch_labels in shuffle_data_loader:
#     # Process the current batch of images and labels
#     print("Batch images shape:", batch_images.shape)
#     print("Batch labels shape:", batch_labels.shape)

#     # Example: Train your model using the current batch
#     # Replace this with your actual training or evaluation code
#     # model.train()  # Set model to training mode
#     # optimizer.zero_grad()  # Clear gradients
#     # predictions = model(batch_images)  # Forward pass
#     # loss = criterion(predictions, batch_labels)  # Calculate loss
#     # loss.backward()  # Backpropagation
#     # optimizer.step()  # Update weights

#     # Break the loop for demonstration (remove for actual training)
#     break



# # List all the files and folders in the data directory
# files_and_folders = os.listdir(data_path)

# # Print the files and folders
# print(files_and_folders)

# data_path='data/PlantVillage'
# def folder_filter(folder):
#     valid_folders = ['Potato___healthy', 'Potato___Early_blight','Potato___Late_blight']
#     return folder in valid_folders
# transform=transforms.Compose([
#     transforms.Resize((224,224)),
#     transforms.ToTensor()
# ])
# # Load dataset using DatasetFolder with custom folder filter and transformations
# dataset = DatasetFolder(root=data_path, loader=torchvision.datasets.folder.default_loader,
#                         transform=transform, is_valid_file=folder_filter)
# print(dataset.classes)
# print(dataset.class_to_idx)
# image,label=dataset[0]
# print("Image shape:", image.shape)
# print("Label (class index):", label)
# print("Label (class name):", dataset.classes[label])

# import torch
# import torchvision.transforms as transforms
# from torchvision.datasets import DatasetFolder
# import os

# # Define the path to the root folder containing subfolders for each class
# data_path = 'data/PlantVillage'

# # Define a custom function to filter and load specific folders
# def folder_filter(folder):
#     valid_folders = ['Potato___healthy', 'Potato___Early_blight', 'Potato___Late_blight']
#     return folder in valid_folders

# # Define transformations to apply to each image
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),  # Resize image to (224, 224)
#     transforms.ToTensor()  # Convert image to PyTorch tensor (normalized to range [0, 1])
# ])

# # Load dataset using DatasetFolder with custom folder filter and transformations
# dataset = DatasetFolder(root=data_path, loader=torchvision.datasets.folder.default_loader,
#                         transform=transform, is_valid_file=folder_filter)

# # Check dataset size
# print("Dataset size:", len(dataset))

# # Print class names (folders within the root directory)
# print("Class names:", dataset.classes)

# # Print class indices
# print("Class indices:", dataset.class_to_idx)

# # Access individual data samples
# # For example, accessing the first data sample
# image, label = dataset[0]
# print("Image shape:", image.shape)
# print("Label (class index):", label)
# print("Label (class name):", dataset.classes[label])

# import os

# # Define the path to the root folder containing subfolders for each class
# data_path = 'data/PlantVillage'

# # Define a custom function to filter and load specific folders
# def folder_filter(folder):
#     valid_folders = ['Potato___healthy', 'Potato___Early_blight', 'Potato___Late_blight']
#     return folder in valid_folders

# # Inspect the contents of the data_path directory
# files_and_folders = os.listdir(data_path)
# print("Contents of data_path directory:", files_and_folders)

# # Check if the expected folders are present
# expected_folders = ['Potato___healthy', 'Potato___Early_blight', 'Potato___Late_blight']
# for folder in expected_folders:
#     if folder not in files_and_folders:
#         print(f"Folder '{folder}' not found in {data_path}")

# # Print the contents of each valid folder
# for folder in expected_folders:
#     folder_contents = os.listdir(os.path.join(data_path, folder))
#     print(f"Contents of folder '{folder}':", folder_contents)

# import torch
# from torchvision import transforms
# from torchvision.datasets import ImageFolder
# from torch.utils.data import DataLoader
# from torchvision.utils import make_grid
# import matplotlib.pyplot as plt
# import os
# from PIL import Image

# data_path = 'data/PlantVillage'

# # Define a mapping of folder names to labels
# label_map = {
#     'Potato___healthy': 0,
#     'Potato___Early_blight': 1,
#     'Potato___Late_blight': 2
# }

# import torch
# from torchvision.transforms import ToTensor
# from torch.utils.data import Dataset, DataLoader
# from PIL import Image
# import os

# # Define the data path and label mapping
# data_path = 'data/PlantVillage'
# label_map = {
#     'Potato___healthy': 0,
#     'Potato___Early_blight': 1,
#     'Potato___Late_blight': 2
# }

# # Initialize empty lists to store images and labels
# images = []
# labels = []

# # Iterate through each folder in the data path
# for folder_name in os.listdir(data_path):
#     if folder_name in label_map:
#         folder_path = os.path.join(data_path, folder_name)
#         for file_name in os.listdir(folder_path):
#                 # Construct the full path to the image file
#                 image_path = os.path.join(folder_path, file_name)

#                 # Load the image using PIL (Pillow)
#                 image = Image.open(image_path).convert('RGB')

#                 # Append the image and corresponding label to the lists
#                 images.append(image)
#                 labels.append(label_map[folder_name])

# # Define a custom dataset class
# class CustomDataset(Dataset):
#     def __init__(self, images, labels, transform=None):
#         self.images = images
#         self.labels = labels
#         self.transform = transform

#     def __len__(self):
#         return len(self.images)

#     def __getitem__(self, idx):
#         image = self.images[idx]
#         label = self.labels[idx]

#         if self.transform:
#             image = self.transform(image)

#         return image, label

# # Create an instance of CustomDataset with transformations
# transform = ToTensor()  # Convert PIL image to PyTorch tensor
# custom_dataset = CustomDataset(images, labels, transform=transform)

# # Create a DataLoader for the custom dataset
# batch_size = 32
# data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)

# # Test the DataLoader by iterating through a few batches
# for batch_images, batch_labels in data_loader:
#     print("Batch images shape:", batch_images.shape)
#     print("Batch labels:", batch_labels)
#     break  # Stop after processing the first batch for demonstration

# class CustomDataset(torch.utils.data.Dataset):
#     def __init__(self, images, labels, transform=None):
#         self.images = images
#         self.labels = labels
#         self.transform = transform

#     def __len__(self):
#         return len(self.images)

#     def __getitem__(self, idx):
#         image = self.images[idx]
#         label = self.labels[idx]

#         if self.transform:
#             image = self.transform(image)

#         return image, label

# custom_dataset = CustomDataset(images, labels, transform=transforms.ToTensor())

# print(len(custom_dataset))

